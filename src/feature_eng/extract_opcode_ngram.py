import sys
sys.path.insert(0, '../helpers')
from util import save_obj, log_exception, progress_bar, load_config

from sklearn.feature_extraction import DictVectorizer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer

import pandas as pd
import numpy as np
import logging
import subprocess
import gzip
import re

# load configuration (../helpers/util.py -> load_config())
conf = load_config("../../config.yml")

# hardcoded primary x86 registers
registers_x86 = ['eax', 'ebx', 'ecx', 'edx', 'esi', 'edi', 'ebp', 'esp'] 

'''
Transforms the highly verbose IDA Pro .asm generated file into a more concise
representation which facilitates the extraction of assembly x86 features (i.e
registers count, opcodes sequence). Following function runs only on UNIX-based
systems.
'''
def extract_clean_asm_lines(asm_file):
    # unix commands are prefered for performance issues
    cleanup_command = 'bash -c "zgrep -E \'^.{10,15} [0-9A-F]{2} *\' ' + asm_file \
            + ' | cut -d \';\' -f1' + ' | sed \'s/\\t/           /g\'' \
            + ' | cut -c100-200' + ' | sed -e \'s/^[ \\t]*//\'' \
            + ' | tr -s [:blank:]"'
    proc = subprocess.Popen([cleanup_command], shell=True, stdout=subprocess.PIPE)
    opcode_lines = proc.communicate()[0].decode('ISO-8859-1').split('\n')
    return opcode_lines


def opcode_ngram_count(asm_file, n):
    """
    Calculates the number of occurences of each distinct opcode present in the .asm
    file generated by IDA Pro. Returns the result as a dictionary.

    Parameters
    ----------
    asm_file: str
        The file name of an IDA Pro generated .asm file
    n: int
        The number of grams to be analyzed

    Returns
    -------
    dict
        The dictionary containing number of occurences of each
        distinct opcode present in the .asm file
    """
    asm_lines = extract_clean_asm_lines(asm_file)
    opcode_seq = []
    # extract the opcode sequence as a list
    for line in asm_lines:
        # relies on clean format of assembly code
        opcode_mnem = line.split(' ')[0].rstrip()
        # reduce the possibility of invalid opcode occurence
        is_valid_opcode = bool(re.match('^[a-z]{2,7}$', opcode_mnem))
        if is_valid_opcode:
            opcode_seq.append(opcode_mnem)
    # count the occurences of each opcode ngram
    ngram_cnt_d = collections.defaultdict(int)
    for i in range(len(opcode_seq)):
        if len(opcode_seq) < i + n:
            break
        ngram = '-'.join(opcode_seq[i:(i+n)])
        ngram_cnt_d[ngram] += 1
    return ngram_cnt_d


def register_count(asm_file):
    """
    Calculates the number of occurences of each x86 register in a
    file generated by IDA Pro. Returns the result as a dictionary.

    Parameters
    ----------
    asm_file: str
        The file name of an IDA Pro generated .asm file

    Returns
    -------
    dict
        The dictionary containing number of occurences of each
        distinct register present in the .asm file
    """
    asm_lines = extract_clean_asm_lines(asm_file)
    reg_cnt_d = dict.fromkeys(registers_x86, 0)
    for line in asm_lines:
        for reg in registers_x86:
            if reg in line:
                reg_cnt_d[reg] += 1
    return reg_cnt_d
    

def extract_opcode_ngrams(files_list, n):
    opcode_d_list = []
    for idx, file_name in enumerate(files_list):
        asm_file = conf['dataset_dir'] + file_name + '.asm.gz'
        opcode_count = opcode_ngram_count(asm_file, n)
        opcode_d_list.append(opcode_count)
        progress_bar(idx+1, len(files_list), 50)
    # convert list of dictionaries to an opcode count numpy array
    vec = DictVectorizer()
    opc_freq = vec.fit_transform(opcode_d_list).toarray()
    opc_freq = pd.DataFrame(opc_freq, columns=vec.get_feature_names())
    csv_file = conf['featsets_dir'] + str(n) + 'gram_opcode_freq.csv'
    opc_freq.to_csv(csv_file)
    # transform ngram frequency array to ngram tfidf array
    transformer = TfidfTransformer(smooth_idf=False)
    opc_tfidf = transformer.fit_transform(opc_freq)
    opc_tfidf = pd.DataFrame(opc_tfidf.todense(), columns=vec.get_feature_names())
    csv_file = conf['featsets_dir'] + str(n) + 'gram_opcode_tfidf.csv'
    opc_tfidf.to_csv(csv_file) 


# The opcode frequency and TFIDF .csv files need to be generated
# prior to this function's invocation
def extract_opcode_subset(opcodes):
    """
    Extracts and stores as CSV files two new feature sets that contain
    the frequency and TF*IDF *only* for the opcodes given in the list

    Parameters
    ----------
    opcodes: list
        The list holding the opcodes that will comprise the new feature set
    """
    # TODO: stop slacking and implement this 
    pass

    

def extract_reg_counts(files_list):
    reg_cnt_d_list = []
    for idx, file_name in enumerate(files_list):
        asm_file = conf['dataset_dir'] + file_name + '.asm.gz'
        reg_cnt = register_count(asm_file)
        reg_cnt_d_list.append(reg_cnt)
        progress_bar(idx+1, len(files_list), 50)
    # convert list of dictionaries to an opcode count numpy array
    vec = DictVectorizer()
    reg_freq = vec.fit_transform(reg_cnt_d_list).toarray()
    reg_freq = pd.DataFrame(reg_freq, columns=vec.get_feature_names())
    csv_file = conf['featsets_dir'] + 'reg_freq.csv'
    reg_freq.to_csv(csv_file)
    # transform ngram frequency array to ngram tfidf array
    transformer = TfidfTransformer(smooth_idf=False)
    reg_tfidf = transformer.fit_transform(reg_freq)
    reg_tfidf = pd.DataFrame(reg_tfidf.todense(), columns=vec.get_feature_names())
    csv_file = conf['featsets_dir'] + 'reg_tfidf.csv'
    reg_tfidf.to_csv(csv_file) 


def extract_opcode_ngram(files_list, n):
    dicts_list = []
    total_files = len(files_list)
    for idx, file_name in enumerate(files_list):
        asm_file = conf['dataset_dir'] + file_name + '.asm.gz'
        clean_asm_code = clean_asm_lines(asm_file)
        opcode_sequence = [] 
        # this loop constructs a sequence of opcodes delimited by space character
        for line in clean_asm_code:
            # below commands works assuming that the preprocessing of the .asm
            # file has already occured
            opcode_mnem = line.split(' ')[0].rstrip()
            # further condition to minimize the number of outliers (handle extreme cases)
            is_valid_opcode = bool(re.match('^[a-z]{2,7}$', opcode_mnem))
            if is_valid_opcode:
                opcode_sequence.append(opcode_mnem)

        ngram_dict = {} 
        for index, opcode in enumerate(opcode_sequence):
            if (n + index) > len(opcode_sequence):
                break
            opcode_ngram = ""
            for j in range(index, index + n):
                opcode_ngram += opcode_sequence[j] + '-'
            # remove trailing '-' char from opcode_ngram
            opcode_ngram = opcode_ngram[:-1]
            if opcode_ngram in ngram_dict:
                ngram_dict[opcode_ngram] += 1
            else:
                ngram_dict[opcode_ngram] = 1

        dicts_list.append(ngram_dict)
        # progress bars always save my sanity
        progress_bar(idx+1, total_files, 50)
    
    # convert list of dictionaries to an opcode ngram count numpy array
    vec = DictVectorizer()
    ngram_freq = vec.fit_transform(dicts_list).toarray()
    ngram_freq_df = pd.DataFrame(ngram_freq, columns=vec.get_feature_names())
    ngram_freq_df.to_csv('features/' + str(n) + 'gram_opcode_freq1.csv', index=False)
    save_obj(ngram_freq_df, str(n) + 'gram_opcode_freq')
    # transform ngram frequency array to ngram tfidf array
    transformer = TfidfTransformer(smooth_idf=False)
    ngram_tfidf = transformer.fit_transform(ngram_freq)
    # transform array to pandas dataframe
    freq_vec_df = pd.DataFrame(ngram_tfidf.todense(), columns=vec.get_feature_names())
    freq_vec_df.to_csv('features/' + str(n) + 'gram_opcode_tfidf1.csv', index=False)
    save_obj(freq_vec_df, str(n) + 'gram_opcode_tfidf')
    return freq_vec_df


train_labels = pd.read_csv(conf['train_labels'])
files_list = train_labels['Id'].tolist()
extract_reg_counts(files_list)

