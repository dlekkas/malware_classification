from util import save_obj, log_exception, progress_bar

from sklearn.feature_extraction import DictVectorizer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer

import pandas as pd
import numpy as np
import logging
import subprocess
import sys
import gzip
import re

DATASET_DIR = '/media/dimlek/\'TOSHIBA EXT\'/malware/'


'''
Function responsible to parse a .asm file disassembled by the IDA pro
software and capture each command's (opcode mnemonic) number of occurrences
:param file: .asm file produced by IDA pro (compressed with .gz)
:returns: dictionary with all opcode mnemonics as keys and their frequencies as values
'''
def extract_opcode_ngram(files_list, n):
    dicts_list = []
    total_files = len(files_list)
    for idx, file_name in enumerate(files_list):
        asm_file = DATASET_DIR + 'train/' + file_name + '.asm.gz'
        # asm file will be formatted accordingly with unix commands
        # to optimize feature extraction time
        clean_command = 'bash -c "zgrep -E \'^.{10,15} [0-9A-F]{2} *\' ' + asm_file \
                + ' | cut -d \';\' -f1' + ' | sed \'s/\\t/           /g\'' \
                + ' | cut -c100-200' + ' | sed -e \'s/^[ \\t]*//\'' \
                + ' | tr -s [:blank:]"'
        proc = subprocess.Popen([clean_command], shell=True, stdout=subprocess.PIPE)
        opcode_lines = proc.communicate()[0].decode('ISO-8859-1').split('\n')
        opcode_sequence = [] 
        # this loop constructs a sequence of opcodes delimited by space character
        for line in opcode_lines:
            # below commands works assuming that the preprocessing of the .asm
            # file has already occured
            opcode_mnem = line.split(' ')[0].rstrip()
            # further condition to minimize the number of outliers (handle extreme cases)
            is_valid_opcode = bool(re.match('^[a-z]{2,7}$', opcode_mnem))
            if is_valid_opcode:
                opcode_sequence.append(opcode_mnem)

        ngram_dict = {} 
        for index, opcode in enumerate(opcode_sequence):
            if (n + index) > len(opcode_sequence):
                break
            opcode_ngram = ""
            for j in range(index, index + n):
                opcode_ngram += opcode_sequence[j] + '-'
            # remove trailing '-' char from opcode_ngram
            opcode_ngram = opcode_ngram[:-1]
            if opcode_ngram in ngram_dict:
                ngram_dict[opcode_ngram] += 1
            else:
                ngram_dict[opcode_ngram] = 1

        dicts_list.append(ngram_dict)
        # progress bars always save my sanity
        progress_bar(idx+1, total_files, 50)
    
    # convert list of dictionaries to an opcode ngram count numpy array
    vec = DictVectorizer()
    ngram_freq = vec.fit_transform(dicts_list).toarray()
    ngram_freq_df = pd.DataFrame(ngram_freq, columns=vec.get_feature_names())
    ngram_freq_df.to_csv('features/' + str(n) + 'gram_opcode_freq.csv', index=False)
    save_obj(ngram_freq_df, str(n) + 'gram_opcode_freq')
    # transform ngram frequency array to ngram tfidf array
    transformer = TfidfTransformer(smooth_idf=False)
    ngram_tfidf = transformer.fit_transform(ngram_freq)
    # transform array to pandas dataframe
    freq_vec_df = pd.DataFrame(ngram_tfidf.todense(), columns=vec.get_feature_names())
    freq_vec_df.to_csv('features/' + str(n) + 'gram_opcode_tfidf.csv', index=False)
    save_obj(freq_vec_df, str(n) + 'gram_opcode_tfidf')
    return freq_vec_df


def main():
    train_labels = pd.read_csv('/home/dimlek/Documents/thesis/dataset/dataSample/trainLabels.csv')
    files_list = train_labels['Id'].tolist()
    # canclulate TF*IDF of each opcode
    extract_opcode_ngram(files_list, 1)

if __name__ == "__main__":
    main()
