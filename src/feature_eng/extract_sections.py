import pandas as pd
import time
import sys
import re
import gzip
import subprocess

sys.path.insert(0, '../helpers')

from util import *

# load configuration file
conf = load_config('../../config.yml') 

# The list below contains all the reserved sections related to PE format
# described explicitly in the official Microsoft Docs:
# https://docs.microsoft.com/en-us/windows/desktop/Debug/pe-format#special-sections
# Additional sections used by compiler optimizations are added aswell:
# https://software.intel.com/en-us/forums/intel-c-compiler/topic/538478
pe_sections = ['.bss', '.cormeta', '.data', '.debug$F', '.debug$P',
        '.debug$P', '.debug$S', '.debug$T', '.drective', '.edata',
        '.idata', '.idlsym', '.pdata', '.reloc', '.rsrc', '.sbss',
        '.sdata', '.srdata', '.sxdata', '.text', '.tls', '.tls$',
        '.vsdata', '.xdata', '.rdata', '.orpc', '.data1', '.text1',
        '_RDATA', '.debug_o', 'HEADER', 'DATA', 'CODE', 'BSS', '.init.']

# Packer section names and tools. For further reference:
# http://www.hexacorn.com/blog/2016/12/15/pe-section-names-re-visited/
pack_sections = ['.aspack', '.aspack1', '.aspack3', '.aspack6',
        '.pack1', '.unpack', '.adata']

# Function that extracts all the sections appearing in the whole group of .asm files
# in Microsoft's Malware Competition. To ensure semantic value of those sections, we
# assert that those sections discovered are valid sections of the PE format.
# Returns a list of all different valid sections appearing in .asm files provided
def extract_legit_sections(files_list):
    total_files = len(files_list)    
    sections_set = set()
    for idx, file_name in enumerate(files_list):
        asm_file = conf['dataset_dir'] + file_name + '.asm.gz'
        try:
            # encoding of .asm files produced by IDA Pro is ISO-8859-1
            with gzip.open(asm_file, 'rt', encoding='ISO-8859-1') as fp:
                for line in fp.readlines():
                    # section name is the first field before ':' in every line
                    # and is converted to lower case for data homogeneity
                    section_name = line.split(':')[0]
                    sections_set.add(section_name)
        except Exception as e:
            log_exception(e, sys.argv[0], asm_file)
        # just to make it fancy
        progress_bar(idx+1, total_files, 50)

    # TODO: for further examination
    save_obj(sections_set, 'sections_interim')
    # intersect the valid PE format sections and the sections that appeared in the .asm files
    # in order to consider only valid sections with actual value
    sections_final = sections_set.intersection(set(pe_sections))
    sections_final = list(sections_final)
    save_obj(sections_final, 'sections')
    return sections_final


# Feature extraction implemented using UNIX's grep command for faster
# extraction. Function returns all sections with an available virtual
# and raw section size.
def extract_vsrs_sections(files_list):
    vsrs_sections = set()
    total_files = len(files_list)
    for idx, file_name in enumerate(files_list):
        asm_file = conf['dataset_dir'] + file_name + '.asm.gz'
        proc_vs = subprocess.run(['zgrep', 'Virtual size', asm_file], stdout=subprocess.PIPE)
        proc_ss = subprocess.run(['zgrep', 'Section size', asm_file], stdout=subprocess.PIPE)
        output_vs = proc_vs.stdout.decode('ISO-8859-1')
        output_ss = proc_ss.stdout.decode('ISO-8859-1')
        sect_vs_list = []; sect_ss_list = []
        for line in output_vs.split('\n')[:-1]:
            section_name = line.split(':')[0]
            # extract virtual size using REGEX (refer to IDA .asm generated file format)
            regexp_vs = re.search('\(\s*(\d+)\.\)', line)
            if regexp_vs:
                sect_vs = int(regexp_vs.group(1))
                sect_vs_list.append(section_name)
        for line in output_ss.split('\n')[:-1]:
            section_name = line.split(':')[0]
            # extract raw size using REGEX (refer to IDA .asm generated file format)
            regexp_ss = re.search('\(\s*(\d+)\.\)', line)
            if regexp_ss:
                sect_ss = int(regexp_ss.group(1))
                sect_ss_list.append(section_name)

        # section should be considered 'legit' only if both virtual size and raw section
        # size is provided is the .asm file
        inter_set = set(sect_vs_list).intersection(set(sect_ss_list))
        vsrs_sections = vsrs_sections.union(inter_set)
        progress_bar(idx+1, total_files, 50)

    save_obj(list(vsrs_sections), 'vsrs_sections')
    return list(vsrs_sections)



# Sections information extraction using unix commands to speed-up the process
def extract_sections_info(sect_dict, files_list):
    # extract_vsrs_sections() must be executed prior to this command
    vsrs_set = set(load_obj('vsrs_sections'))
    vsrs_sections = list(vsrs_set.intersection(set(pe_sections)))
    # extract_legit_sections() must be executed prior to this command
    legit_sections = load_obj('sections')
    total_files = len(files_list)

    section_xtimes = []
    for idx, file_name in enumerate(files_list):
        for key in sect_dict:
            sect_dict[key].append(0)
        asm_file = conf['dataset_dir'] + file_name + '.asm.gz'
        
        start = time.time()

        lines_proc = subprocess.run(['zgrep', '-c', '^', asm_file], stdout=subprocess.PIPE)
        total_lines = int(lines_proc.stdout.decode('ISO-8859-1').strip())
        for section in legit_sections:
            # extract lines of the specific section
            grep_regex = '^\\' + section + ':'
            proc = subprocess.run(['zgrep', '-c', grep_regex, asm_file], stdout=subprocess.PIPE)
            sect_lines = int(proc.stdout.decode('ISO-8859-1').strip())
            sect_dict[section + '_linesperc'][idx] = float(sect_lines)/total_lines

        proc_vs = subprocess.run(['zgrep', 'Virtual size', asm_file], stdout=subprocess.PIPE)
        proc_ss = subprocess.run(['zgrep', 'Section size', asm_file], stdout=subprocess.PIPE)
        output_vs = proc_vs.stdout.decode('ISO-8859-1')
        output_ss = proc_ss.stdout.decode('ISO-8859-1')
        for line in output_vs.split('\n')[:-1]:
            section_name = line.split(':')[0]
            if section_name not in vsrs_sections:
                continue
            # extract virtual size using REGEX (refer to IDA .asm generated file format)
            regexp_vs = re.search('\(\s*(\d+)\.\)', line)
            if regexp_vs:
                sect_vs = int(regexp_vs.group(1))
                sect_dict[section_name + '_vs'][idx] = sect_vs
        
        total_vs = sum(sect_dict[s + '_vs'][idx] for s in vsrs_sections)
        if total_vs != 0:
            for section in vsrs_sections:
                sect_dict[section + '_vsperc'][idx] = float(sect_dict[section + '_vs'][idx])/total_vs
    
        for line in output_ss.split('\n')[:-1]:
            section_name = line.split(':')[0]
            if section_name not in vsrs_sections:
                continue
            # extract raw size using REGEX (refer to IDA .asm generated file format)
            regexp_ss = re.search('\(\s*(\d+)\.\)', line)
            if regexp_ss:
                sect_ss = int(regexp_ss.group(1))
                # TODO: find more clever similarity function
                if sect_ss != 0:
                    sim = float(sect_dict[section_name + '_vs'][idx] - sect_ss)/sect_ss
                    sect_dict[section_name + '_vsrs_sim'][idx] = sim


        end = time.time()
        section_xtimes.append(end - start)
        progress_bar(idx+1, total_files, 50)

    save_obj(section_xtimes, "section_xtimes") 
    sections_pd = pd.DataFrame.from_dict(sect_dict)
    sections_pd.to_csv(conf['featsets_dir'] + 'section_features.csv', index=False)
    save_obj(sections_pd, 'section_features')
    return sections_pd


def sections_features_exper():
    # extract_vsrs_sections() must be executed prior to this command
    vsrs_l = load_obj('vsrs_sections')
    vsrs_set = set(load_obj('vsrs_sections'))
    vsrs_sections = list(vsrs_set.intersection(set(pe_sections)))

    # extract_legit_sections() must be executed prior to this command
    legit_sections = load_obj('sections') + packing_sections
    total_files = len(files_list)
    for idx, file_name in enumerate(files_list):
        for key in sect_dict:
            sect_dict[key].append(0)
        asm_file = conf['dataset_dir'] + file_name + '.asm.gz'
        lines_proc = subprocess.run(['zgrep', '-c', '^', asm_file], stdout=subprocess.PIPE)
        total_lines = int(lines_proc.stdout.decode('ISO-8859-1').strip())
        legit_lines = 0
        for section in legit_sections:
            # extract lines of the specific section
            grep_regex = '^\\' + section + ':'
            proc = subprocess.run(['zgrep', '-c', grep_regex, asm_file], stdout=subprocess.PIPE)
            sect_lines = int(proc.stdout.decode('ISO-8859-1').strip())
            legit_lines += sect_lines
            # group all
            if section in pack_sections:
                sect_dict['packing_linesperc'][idx] = float(sect_lines)/total_lines
            else:
                sect_dict[section + '_linesperc'][idx] = float(sect_lines)/total_lines
        sect_dict['unknown_linesperc'][idx] = float(total_lines - legit_lines)/total_lines 

        proc_vs = subprocess.run(['zgrep', 'Virtual size', asm_file], stdout=subprocess.PIPE)
        proc_ss = subprocess.run(['zgrep', 'Section size', asm_file], stdout=subprocess.PIPE)
        output_vs = proc_vs.stdout.decode('ISO-8859-1')
        output_ss = proc_ss.stdout.decode('ISO-8859-1')
        for line in output_vs.split('\n')[:-1]:
            section_name = line.split(':')[0]
            if section_name not in vsrs_l:
                continue
            # extract virtual size using REGEX (refer to IDA .asm generated file format)
            regexp_vs = re.search('\(\s*(\d+)\.\)', line)
            if regexp_vs:
                sect_vs = int(regexp_vs.group(1))
                # group all sections for packing together and take them into account as
                # a unified section rather than distinct ones for different packing software
                if section_name in pack_sections:
                    sect_dict['packing_vs'][idx] = sect_vs
                # calculate all distinct legit sections with a specified virtual and raw size
                elif section_name in pe_sections:
                    sect_dict[section_name + '_vs'][idx] = sect_vs
                # group all unknown sections together and consider them as a unified section
                # with obfuscated section names
                else:
                    sect_dict['unknown_vs'][idx] = sect_vs
        
        total_vs = sum(sect_dict[s + '_vs'][idx] for s in vsrs_sections)
        if total_vs != 0:
            for section in vsrs_sections:
                sect_dict[section + '_vsperc'][idx] = float(sect_dict[section + '_vs'][idx])/total_vs
    
        for line in output_ss.split('\n')[:-1]:
            section_name = line.split(':')[0]
            if section_name not in vsrs_sections:
                continue
            # extract raw size using REGEX (refer to IDA .asm generated file format)
            regexp_ss = re.search('\(\s*(\d+)\.\)', line)
            if regexp_ss:
                sect_ss = int(regexp_ss.group(1))
                # TODO: find more clever similarity function
                if sect_ss != 0:
                    if section_name in pack_sections:
                        sim = float(sect_dict['packing_vs'][idx] - sect_ss)/sect_ss
                        sect_dict['packing_vsrs_sim'][idx] = sim
                    elif section_name in pe_sections:     
                        sim = float(sect_dict[section_name + '_vs'][idx] - sect_ss)/sect_ss
                        sect_dict[section_name + '_vsrs_sim'][idx] = sim
                    elif section_name in vsrs_sections:
                        sim = float(sect_dict['unknown_vs'][idx] - sect_ss)/sect_ss
                        sect_dict['unknown_vsrs_sim'][idx] = sim
        progress_bar(idx+1, total_files, 50)
    sections_pd = pd.DataFrame.from_dict(sect_dict)
    sections_pd.to_csv(conf['featsets_dir'] + 'section_features_v2.csv')#, index=False)
    return sections_pd


    
# Create a dictionary with keys corresponding to each valid sections, in order to
# count number of occurences and percentage of each section.
def sections_dict_initialization():
    # extract_sections_labels() should be executed prior to this command
    sections_list = load_obj('sections')
    # extract_vsrs_sections() should be executed prior to this commad
    vsrs_set = set(load_obj('vsrs_sections'))
    vsrs_sections = list(vsrs_set.intersection(set(pe_sections))) 
    sections_vs = [s + '_vs' for s in vsrs_sections]
    sections_perc = [s + '_vsperc' for s in vsrs_sections]
    sections_lines = [s + '_linesperc' for s in sections_list]
    # TODO: calculate the similarity between VS and raw size maybe?? 
    # a similarity function implemented in the difference of virtual size and raw size
    sections_sim = [s + '_vsrs_sim' for s in vsrs_sections]
    sections_features = sections_vs + sections_perc + sections_lines + sections_sim
    sect_dict = dict((k, []) for k in sections_features)
    return sect_dict


def extract_segments(): 
    train_labels = pd.read_csv(conf['train_labels'])
    files_list = train_labels['Id'].tolist()
    # extract_legit_sections(files_list)
    # extract_vsrs_sections(files_list)
    sect_dict = sections_dict_initialization()
    extract_sections_info(sect_dict, files_list)

extract_segments()
