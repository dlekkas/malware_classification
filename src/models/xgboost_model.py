from util import save_obj
import xgboost as xgb
import datetime
import uuid

# Further reference to XGBoost Python API from official docs:
# https://xgboost.readthedocs.io/en/latest/python/python_api.html



class XGBoost:


    def __init__(self, booster="gbtree", nthread=-1, verbosity=2, learning_rate=0.3,
            gamma=0, max_depth=2, objective='multi:softmax', num_round=5):
        # general parameters
        self.booster = booster
        self.verbosity = verbosity
        self.nthread = nthread
        self.model_id = str(uuid.uuid4())

        # tree booster parameters
        self.learning_rate = learning_rate
        self.gamma = gamma
        self.max_depth = max_depth
        self.objective = objective
        self.num_round = num_round


    def train(self, train_data, labels):
        # replace missing values with 0 - sanity check
        dtrain = xgb.DMatrix(train_data, label = labels, missing=0.0)
        # model parameters 
        params = {'booster': self.booster, 'verbosity': self.verbosity, 
                'nthread': self.nthread, 'eta': self.learning_rate,
                'gamma': self.gamma, 'max_depth': self.max_depth,
                'objective': self.objective, 'num_class': 9}
        self.bst = xgb.train(params, dtrain, self.num_round)


    # save model to file & save pickle Booster object to retain feature_names
    def save_model():
        model_file = "_".join(["XGBooster", self.model_id, ".model"])
        pickle_file = "_".join(["XGBooster", self.model_id])
        self.bst.save_model(model_file)
        save_obj(self.bst, pickle_file)


    def predict(self, test_data):
        dtest = xgb.DMatrix(test_data, missing=0.0)
        ypred =  self.bst.predict(dtest, ntree_limit=bst.best_ntree_limit)
        return ypred






   
